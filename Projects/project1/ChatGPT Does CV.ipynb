{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12be4ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: Read in an image from a file\n",
    "# Prompt: \"Write a Python program to read in an image from a file\"\n",
    "\n",
    "# ChatGPT response code:\n",
    "from PIL import Image\n",
    "\n",
    "# Open the image file\n",
    "with Image.open(\"image.jpg\") as im:\n",
    "    # Display the image\n",
    "    im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86e4df9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 2: Resize an image\n",
    "# Prompt: \"Now, I would like you to write a Python program that resizes an arbitrary input image to have dimensions 256x256\"\n",
    "\n",
    "# ChatGPT response\n",
    "import cv2\n",
    "\n",
    "# Read in the image\n",
    "im = cv2.imread(\"image.jpg\")\n",
    "\n",
    "# Resize the image\n",
    "im_resized = cv2.resize(im, (256, 256))\n",
    "\n",
    "# Save the resized image\n",
    "cv2.imwrite(\"image_resized.jpg\", im_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8c1f860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 3: Rotate and image\n",
    "# Prompt: Using the openCV library, write a program which rotates an image and then saves it\n",
    "\n",
    "# ChatGPT response:\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read in the image\n",
    "im = cv2.imread(\"image.jpg\")\n",
    "\n",
    "# Get the image height and width\n",
    "(h, w) = im.shape[:2]\n",
    "\n",
    "# Define the center of the image\n",
    "center = (w / 2, h / 2)\n",
    "\n",
    "# Define the angle of rotation (in degrees)\n",
    "angle = 90\n",
    "\n",
    "# Define the scale of the image\n",
    "scale = 1.0\n",
    "\n",
    "# Perform the rotation\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "rotated_image = cv2.warpAffine(im, rotation_matrix, (w, h))\n",
    "\n",
    "# Save the rotated image\n",
    "cv2.imwrite(\"image_rotated.jpg\", rotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "944342b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 4: Sharpen an image\n",
    "# Prompt: Using the openCV library, write a program to sharpen an image and then save it\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('image_blurred.jpg')\n",
    "\n",
    "# Create the sharpening kernel, it must be odd\n",
    "kernel_sharpening = np.array([[-1,-1,-1], \n",
    "                              [-1, 9,-1], \n",
    "                              [-1,-1,-1]])\n",
    "\n",
    "# Apply the kernel to the image\n",
    "sharpened = cv2.filter2D(image, -1, kernel_sharpening)\n",
    "\n",
    "# Save the sharpened image\n",
    "cv2.imwrite('image_sharpened.jpg', sharpened)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4941b374",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/imgproc/src/smooth.dispatch.cpp:294: error: (-215:Assertion failed) ksize.width > 0 && ksize.width % 2 == 1 && ksize.height > 0 && ksize.height % 2 == 1 in function 'createGaussianKernels'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Blur the image using a Gaussian filter\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m image_blurred \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGaussianBlur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Save the blurred image\u001b[39;00m\n\u001b[1;32m     14\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_blurred.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, image_blurred)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/imgproc/src/smooth.dispatch.cpp:294: error: (-215:Assertion failed) ksize.width > 0 && ksize.width % 2 == 1 && ksize.height > 0 && ksize.height % 2 == 1 in function 'createGaussianKernels'\n"
     ]
    }
   ],
   "source": [
    "# Question 5: Blur an image\n",
    "# Prompt: Using the openCV library, write a program to blur an image\n",
    "\n",
    "# ChatGPT response\n",
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('image.jpg')\n",
    "\n",
    "# Blur the image using a Gaussian filter\n",
    "image_blurred = cv2.GaussianBlur(image, (10, 10), 0)\n",
    "\n",
    "# Save the blurred image\n",
    "cv2.imwrite('image_blurred.jpg', image_blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035331eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 6: Convert a color image into a greyscale image\n",
    "# Prompt: Using Python, convert a color image into a greyscale image\n",
    "\n",
    "# ChatGPT response\n",
    "import cv2\n",
    "\n",
    "# Load the color image\n",
    "image = cv2.imread('image.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Save the grayscale image\n",
    "cv2.imwrite('grayscale_image.jpg', gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc821fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 7: Detect edges\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('image.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply the Canny edge detection algorithm\n",
    "edges = cv2.Canny(gray_image, 100, 200)\n",
    "\n",
    "# Save the edge image\n",
    "cv2.imwrite('edges.jpg', edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d1822cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 8: Detect faces\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Load the input image\n",
    "img = cv2.imread(\"faces_input.jpg\")\n",
    "\n",
    "# Convert the input image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the grayscale image\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "# Draw rectangles around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "# Save the result to an output image\n",
    "cv2.imwrite(\"faces_output.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2df2e6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detect cars\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the HOG descriptor\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "# Load the input image\n",
    "img = cv2.imread(\"cars.jpg\")\n",
    "\n",
    "# Run the HOG descriptor on the input image to detect cars\n",
    "boxes, weights = hog.detectMultiScale(img, winStride=(8, 8), padding=(32, 32), scale=1.05)\n",
    "\n",
    "# Draw rectangles around the detected cars\n",
    "for (x, y, w, h) in boxes:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "# Save the result to an output image\n",
    "cv2.imwrite(\"cars_output.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a755dde",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnimplementedError",
     "evalue": "File system scheme 'http' not implemented (file: 'http://github.com/tensorflow/tensorflow/blob/r2.4/tensorflow/lite/examples/images/dog_vs_cat_model.tflite?raw=true')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Download the pre-trained deep learning model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://github.com/tensorflow/tensorflow/blob/r2.4/tensorflow/lite/examples/images/dog_vs_cat_model.tflite?raw=true\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Load the input image\u001b[39;00m\n\u001b[1;32m     12\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdog.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/tensorflow/python/lib/io/file_io.py:288\u001b[0m, in \u001b[0;36mfile_exists_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"Determines whether a path exists or not.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03m>>> with open(\"/tmp/x\", \"w\") as f:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m  errors.OpError: Propagates any errors reported by the FileSystem API.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m   _pywrap_file_io\u001b[38;5;241m.\u001b[39mFileExists(compat\u001b[38;5;241m.\u001b[39mpath_to_bytes(path))\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError:\n\u001b[1;32m    290\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: File system scheme 'http' not implemented (file: 'http://github.com/tensorflow/tensorflow/blob/r2.4/tensorflow/lite/examples/images/dog_vs_cat_model.tflite?raw=true')"
     ]
    }
   ],
   "source": [
    "# Classify dog vs. cat\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Download the pre-trained deep learning model\n",
    "url = \"https://github.com/tensorflow/tensorflow/blob/r2.4/tensorflow/lite/examples/images/dog_vs_cat_model.tflite?raw=true\"\n",
    "model = tf.keras.models.load_model(url)\n",
    "\n",
    "# Load the input image\n",
    "img = cv2.imread(\"dog.jpg\")\n",
    "img = cv2.resize(img, (224, 224))\n",
    "img = np.reshape(img, [1, 224, 224, 3])\n",
    "\n",
    "# Perform prediction using the deep learning model\n",
    "prediction = model.predict(img)\n",
    "\n",
    "# Get the class label with the highest predicted probability\n",
    "class_index = np.argmax(prediction[0])\n",
    "class_label = \"dog\" if class_index == 1 else \"cat\"\n",
    "\n",
    "# Print the prediction result\n",
    "print(\"The image is of a\", class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd74805b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35 93 44 33]\n",
      " [15 35 17 14]\n",
      " [32 42 26 35]]\n",
      "[[15 45 24 23]\n",
      " [42 74 47 62]\n",
      " [31 31 26 46]]\n",
      "[[ 20  48  20  10]\n",
      " [-27 -39 -30 -48]\n",
      " [  1  11   0 -11]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[4,2,3,7],\n",
    "              [3,5,2,1],\n",
    "              [1,9,4,2]])\n",
    "\n",
    "b = np.array([[2,7,6],\n",
    "              [1,3,2],\n",
    "              [4,5,1]])\n",
    "\n",
    "q1 = b@a\n",
    "q2 = (a.T@b).T\n",
    "\n",
    "print(q1)\n",
    "print(q2)\n",
    "print(np.subtract(q1, q2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
